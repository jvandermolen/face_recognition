import numpy as np
import cv2
import cv2.cv as cv
from video import create_capture
from common import clock, draw_str
import os, errno
import time

help_message = '''
USAGE: facedetect.py [--cascade <cascade_fn>] [--nested-cascade <cascade_fn>] [--frame-interval <n_of_frames>] [<video_source>]
'''

def mkdir(path):
    try:
        os.makedirs(path)
    except OSError as exception:
        if exception.errno != errno.EEXIST:
            raise

def detect(img, cascade):
    rects = cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=4, minSize=(30, 30), flags = cv.CV_HAAR_SCALE_IMAGE)
    if len(rects) == 0:
        return []
    rects[:,2:] += rects[:,:2]
    return rects

def draw_rects(img, rects, color):
    for x1, y1, x2, y2 in rects:
        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)

if __name__ == '__main__':
    start = time.clock() #para medir el tiempo de ejecucion
    import sys, getopt
    print help_message

    args, video_src = getopt.getopt(sys.argv[1:], '', ['cascade=', 'nested-cascade=', 'frame-interval='])
    try: video_src = video_src[0]
    except: video_src = 0
    args = dict(args)
    cascade_fn = args.get('--cascade', "/shared/videos/data/haarcascades/haarcascade_frontalface_alt.xml")
    nested_fn  = args.get('--nested-cascade', "/shared/videos/data/haarcascades/haarcascade_eye.xml")
    cascade2_fn = args.get('--cascade2', "/shared/videos/data/haarcascades/haarcascade_profileface.xml")
    cascade3_fn = args.get('--cascade3', "/shared/videos/data/haarcascades/haarcascade_frontalface_alt2.xml")
    cascade4_fn = args.get('--cascade4', "/shared/videos/data/haarcascades/haarcascade_frontalface_alt_tree.xml")

    cascade = cv2.CascadeClassifier(cascade_fn)
    nested = cv2.CascadeClassifier(nested_fn)
    cascade2 = cv2.CascadeClassifier(cascade2_fn)
    cascade3 = cv2.CascadeClassifier(cascade3_fn)
    cascade4 = cv2.CascadeClassifier(cascade4_fn)

    frame_interval = int(args.get('--frame-interval', 1))

    fields = video_src.split('/')
    outDir = fields[-1]
    prefix = fields[-1]

    mkdir("/shared/videos/faces/" + outDir)

    cam = create_capture(video_src, fallback='synth:bg=../cpp/lena.jpg:noise=0.05')
    i = 0
    frame = 0
    while True:
        for iframe in xrange(frame_interval):
            frame = frame + 1
            ret, img = cam.read()
        if img is None:
            break

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        gray = cv2.equalizeHist(gray)

        #t = clock()
        rects = detect(gray, cascade)
        rects2 = detect(gray, cascade2)
        rects = np.array(list(rects) + list(rects2)) 
        """
        if len(rects) == 0:
            rects = detect(gray, cascade3)
        if len(rects) == 0:
            rects = detect(gray, cascade4)
        """
        vis = img.copy()
        draw_rects(vis, rects, (0, 255, 0))
        
        for x1, y1, x2, y2 in rects:
            vis_roi = img[y1:y2, x1:x2]
            i = i + 1
            print "Face " + str(i) + " - Frame " + str(frame)
            cv2.imwrite("/shared/videos/faces/" + outDir + '/' + prefix + "_" + str(i) + "_" + str(frame) + ".jpg", vis_roi);
            
            roi = gray[y1:y2, x1:x2]
            vis_roi = vis[y1:y2, x1:x2]
            #subrects = detect(roi.copy(), nested)
            #draw_rects(vis_roi, subrects, (255, 0, 0))
        #dt = clock() - t

        #draw_str(vis, (20, 20), 'time: %.1f ms' % (dt*1000))
        #cv2.imshow('facedetect', vis)

        #if 0xFF & cv2.waitKey(5) == 27:
        #    break
    cv2.destroyAllWindows()

    elapsed = time.clock() - start
    hours = int(elapsed/3600)
    minutes = int((elapsed - hours*3600)/60)
    seconds = elapsed - hours*3600 - minutes*60
    
    print 'number of faces: ' + str(i)
    print 'elpased time: ' + str(hours) + ' hours, ' + str(minutes) + ' minutes, ' + str(seconds) + ' seconds.'

